{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c30dfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 384, 80, 80])\n",
      "torch.Size([2, 768, 40, 40])\n",
      "torch.Size([2, 1536, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import copy\n",
    "from collections import OrderedDict\n",
    "\n",
    "S3 = torch.rand(size=(2, 384, 80, 80))\n",
    "S4 = torch.rand(size=(2, 768, 40, 40))\n",
    "S5 = torch.rand(size=(2, 1536, 20, 20))\n",
    "\n",
    "feats = [S3, S4, S5]\n",
    "\n",
    "for i in feats:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfb3b085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256, 80, 80])\n",
      "torch.Size([2, 256, 40, 40])\n",
      "torch.Size([2, 256, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 256\n",
    "input_proj = nn.ModuleList()\n",
    "\n",
    "for input_feat in feats:\n",
    "    in_channel = input_feat.shape[1]\n",
    "    proj = nn.Sequential(OrderedDict([\n",
    "        ('conv', nn.Conv2d(in_channel, hidden_dim, kernel_size=1, bias=False)),\n",
    "        ('norm', nn.BatchNorm2d(hidden_dim))\n",
    "    ]))\n",
    "    \n",
    "    input_proj.append(proj)\n",
    "    \n",
    "proj_feats  = [input_proj[i](feat) for i, feat in enumerate(feats)]\n",
    "\n",
    "for i in proj_feats:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0885ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256, 80, 80])\n",
      "torch.Size([2, 256, 40, 40])\n",
      "torch.Size([2, 256, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "def get_activation(act: str, inpace: bool=True):\n",
    "    \"\"\"get activation\n",
    "    \"\"\"\n",
    "    if act is None:\n",
    "        return nn.Identity()\n",
    "\n",
    "    elif isinstance(act, nn.Module):\n",
    "        return act\n",
    "\n",
    "    act = act.lower()\n",
    "\n",
    "    if act == 'silu' or act == 'swish':\n",
    "        m = nn.SiLU()\n",
    "\n",
    "    elif act == 'relu':\n",
    "        m = nn.ReLU()\n",
    "\n",
    "    elif act == 'leaky_relu':\n",
    "        m = nn.LeakyReLU()\n",
    "\n",
    "    elif act == 'silu':\n",
    "        m = nn.SiLU()\n",
    "\n",
    "    elif act == 'gelu':\n",
    "        m = nn.GELU()\n",
    "\n",
    "    elif act == 'hardsigmoid':\n",
    "        m = nn.Hardsigmoid()\n",
    "\n",
    "    else:\n",
    "        raise RuntimeError('')\n",
    "\n",
    "    if hasattr(m, 'inplace'):\n",
    "        m.inplace = inpace\n",
    "\n",
    "    return m\n",
    "\n",
    "def build_2d_sincos_position_embedding(w, h, embed_dim=256, temperature=10000.):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        grid_w = torch.arange(int(w), dtype=torch.float32)\n",
    "        grid_h = torch.arange(int(h), dtype=torch.float32)\n",
    "        grid_w, grid_h = torch.meshgrid(grid_w, grid_h, indexing='ij')\n",
    "        assert embed_dim % 4 == 0, \\\n",
    "            'Embed dimension must be divisible by 4 for 2D sin-cos position embedding'\n",
    "        pos_dim = embed_dim // 4\n",
    "        omega = torch.arange(pos_dim, dtype=torch.float32) / pos_dim\n",
    "        omega = 1. / (temperature ** omega)\n",
    "\n",
    "        out_w = grid_w.flatten()[..., None] @ omega[None]\n",
    "        out_h = grid_h.flatten()[..., None] @ omega[None]\n",
    "\n",
    "        return torch.concat([out_w.sin(), out_w.cos(), out_h.sin(), out_h.cos()], dim=1)[None, :, :]\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 d_model,\n",
    "                 nhead,\n",
    "                 dim_feedforward=2048,\n",
    "                 dropout=0.1,\n",
    "                 activation=\"relu\",\n",
    "                 normalize_before=False):\n",
    "        super().__init__()\n",
    "        self.normalize_before = normalize_before\n",
    "\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout, batch_first=True)\n",
    "\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.activation = get_activation(activation)\n",
    "\n",
    "    @staticmethod\n",
    "    def with_pos_embed(tensor, pos_embed):\n",
    "        return tensor if pos_embed is None else tensor + pos_embed\n",
    "\n",
    "    def forward(self, src, src_mask=None, pos_embed=None) -> torch.Tensor:\n",
    "        residual = src\n",
    "        if self.normalize_before:\n",
    "            src = self.norm1(src)\n",
    "        q = k = self.with_pos_embed(src, pos_embed)\n",
    "        src, _ = self.self_attn(q, k, value=src, attn_mask=src_mask)\n",
    "\n",
    "        src = residual + self.dropout1(src)\n",
    "        if not self.normalize_before:\n",
    "            src = self.norm1(src)\n",
    "\n",
    "        residual = src\n",
    "        if self.normalize_before:\n",
    "            src = self.norm2(src)\n",
    "        src = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
    "        src = residual + self.dropout2(src)\n",
    "        if not self.normalize_before:\n",
    "            src = self.norm2(src)\n",
    "        return src\n",
    "    \n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, encoder_layer, num_layers, norm=None):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([copy.deepcopy(encoder_layer) for _ in range(num_layers)])\n",
    "        self.num_layers = num_layers\n",
    "        self.norm = norm\n",
    "\n",
    "    def forward(self, src, src_mask=None, pos_embed=None) -> torch.Tensor:\n",
    "        output = src\n",
    "        for layer in self.layers:\n",
    "            output = layer(output, src_mask=src_mask, pos_embed=pos_embed)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            output = self.norm(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "encoder_layer = TransformerEncoderLayer(\n",
    "    hidden_dim,\n",
    "    nhead=8,\n",
    "    dim_feedforward=1024,\n",
    "    dropout=0.0,\n",
    "    activation='silu'\n",
    ")\n",
    "\n",
    "encoder = nn.ModuleList([\n",
    "    TransformerEncoder(copy.deepcopy(encoder_layer), 1) for _ in range(len([2]))\n",
    "])\n",
    "\n",
    "# print(encoder)\n",
    "\n",
    "use_encoder_idx = [2]\n",
    "for i, enc_ind in enumerate(use_encoder_idx):   # 0, 2\n",
    "    h, w = proj_feats[enc_ind].shape[2:]\n",
    "    # [B, C, H, W] to [B, HxW, C]\n",
    "    src_flatten = proj_feats[enc_ind].flatten(2).permute(0, 2, 1)\n",
    "    \n",
    "    pos_embed = build_2d_sincos_position_embedding(w, h, hidden_dim).to(src_flatten.device)\n",
    "    \n",
    "    memory = encoder[i](src_flatten, pos_embed=pos_embed)\n",
    "    proj_feats[enc_ind] = memory.permute(0, 2, 1).reshape(-1, hidden_dim, h, w).contiguous()\n",
    "\n",
    "for i in proj_feats:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d3b46d",
   "metadata": {},
   "source": [
    "## Boardcasting and fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a66e23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNormLayer(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out, kernel_size, stride, g=1, padding=None, bias=False, act=None):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size-1)//2 if padding is None else padding\n",
    "        self.conv = nn.Conv2d(\n",
    "            ch_in,\n",
    "            ch_out,\n",
    "            kernel_size,\n",
    "            stride,\n",
    "            groups=g,\n",
    "            padding=padding,\n",
    "            bias=bias)\n",
    "        self.norm = nn.BatchNorm2d(ch_out)\n",
    "        self.act = nn.Identity() if act is None else get_activation(act)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.norm(self.conv(x)))\n",
    "\n",
    "class ConvNormLayer_fuse(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out, kernel_size, stride, g=1, padding=None, bias=False, act=None):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size-1)//2 if padding is None else padding\n",
    "        self.conv = nn.Conv2d(\n",
    "            ch_in,\n",
    "            ch_out,\n",
    "            kernel_size,\n",
    "            stride,\n",
    "            groups=g,\n",
    "            padding=padding,\n",
    "            bias=bias)\n",
    "        self.norm = nn.BatchNorm2d(ch_out)\n",
    "        self.act = nn.Identity() if act is None else get_activation(act)\n",
    "        self.ch_in, self.ch_out, self.kernel_size, self.stride, self.g, self.padding, self.bias = \\\n",
    "            ch_in, ch_out, kernel_size, stride, g, padding, bias\n",
    "\n",
    "    def forward(self, x):\n",
    "        if hasattr(self, 'conv_bn_fused'):\n",
    "            y = self.conv_bn_fused(x)\n",
    "        else:\n",
    "            y = self.norm(self.conv(x))\n",
    "        return self.act(y)\n",
    "\n",
    "    def convert_to_deploy(self):\n",
    "        if not hasattr(self, 'conv_bn_fused'):\n",
    "            self.conv_bn_fused = nn.Conv2d(\n",
    "                self.ch_in,\n",
    "                self.ch_out,\n",
    "                self.kernel_size,\n",
    "                self.stride,\n",
    "                groups=self.g,\n",
    "                padding=self.padding,\n",
    "                bias=True)\n",
    "\n",
    "        kernel, bias = self.get_equivalent_kernel_bias()\n",
    "        self.conv_bn_fused.weight.data = kernel\n",
    "        self.conv_bn_fused.bias.data = bias\n",
    "        self.__delattr__('conv')\n",
    "        self.__delattr__('norm')\n",
    "\n",
    "    def get_equivalent_kernel_bias(self):\n",
    "        kernel3x3, bias3x3 = self._fuse_bn_tensor()\n",
    "\n",
    "        return kernel3x3, bias3x3\n",
    "\n",
    "    def _fuse_bn_tensor(self):\n",
    "        kernel = self.conv.weight\n",
    "        running_mean = self.norm.running_mean\n",
    "        running_var = self.norm.running_var\n",
    "        gamma = self.norm.weight\n",
    "        beta = self.norm.bias\n",
    "        eps = self.norm.eps\n",
    "        std = (running_var + eps).sqrt()\n",
    "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
    "        return kernel * t, beta - running_mean * gamma / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d62da8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class VGGBlock(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out, act='relu'):\n",
    "        super().__init__()\n",
    "        self.ch_in = ch_in\n",
    "        self.ch_out = ch_out\n",
    "        self.conv1 = ConvNormLayer(ch_in, ch_out, 3, 1, padding=1, act=None)\n",
    "        self.conv2 = ConvNormLayer(ch_in, ch_out, 1, 1, padding=0, act=None)\n",
    "        self.act = nn.Identity() if act is None else get_activation(act)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if hasattr(self, 'conv'):\n",
    "            y = self.conv(x)\n",
    "        else:\n",
    "            y = self.conv1(x) + self.conv2(x)\n",
    "\n",
    "        return self.act(y)\n",
    "\n",
    "    def convert_to_deploy(self):\n",
    "        if not hasattr(self, 'conv'):\n",
    "            self.conv = nn.Conv2d(self.ch_in, self.ch_out, 3, 1, padding=1)\n",
    "\n",
    "        kernel, bias = self.get_equivalent_kernel_bias()\n",
    "        self.conv.weight.data = kernel\n",
    "        self.conv.bias.data = bias\n",
    "        self.__delattr__('conv1')\n",
    "        self.__delattr__('conv2')\n",
    "\n",
    "    def get_equivalent_kernel_bias(self):\n",
    "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.conv1)\n",
    "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.conv2)\n",
    "\n",
    "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1), bias3x3 + bias1x1\n",
    "\n",
    "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
    "        if kernel1x1 is None:\n",
    "            return 0\n",
    "        else:\n",
    "            return F.pad(kernel1x1, [1, 1, 1, 1])\n",
    "\n",
    "    def _fuse_bn_tensor(self, branch: ConvNormLayer):\n",
    "        if branch is None:\n",
    "            return 0, 0\n",
    "        kernel = branch.conv.weight\n",
    "        running_mean = branch.norm.running_mean\n",
    "        running_var = branch.norm.running_var\n",
    "        gamma = branch.norm.weight\n",
    "        beta = branch.norm.bias\n",
    "        eps = branch.norm.eps\n",
    "        std = (running_var + eps).sqrt()\n",
    "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
    "        return kernel * t, beta - running_mean * gamma / std\n",
    "\n",
    "class CSPLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 num_blocks=3,\n",
    "                 expansion=1.0,\n",
    "                 bias=False,\n",
    "                 act=\"silu\",\n",
    "                 bottletype=VGGBlock):\n",
    "        super(CSPLayer, self).__init__()\n",
    "        hidden_channels = int(out_channels * expansion)\n",
    "        self.conv1 = ConvNormLayer_fuse(in_channels, hidden_channels, 1, 1, bias=bias, act=act)\n",
    "        self.conv2 = ConvNormLayer_fuse(in_channels, hidden_channels, 1, 1, bias=bias, act=act)\n",
    "        self.bottlenecks = nn.Sequential(*[\n",
    "            bottletype(hidden_channels, hidden_channels, act=act) for _ in range(num_blocks)\n",
    "        ])\n",
    "        if hidden_channels != out_channels:\n",
    "            self.conv3 = ConvNormLayer_fuse(hidden_channels, out_channels, 1, 1, bias=bias, act=act)\n",
    "        else:\n",
    "            self.conv3 = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_2 = self.conv2(x)\n",
    "        x_1 = self.conv1(x)\n",
    "        x_1 = self.bottlenecks(x_1)\n",
    "        return self.conv3(x_1 + x_2)\n",
    "\n",
    "class RepNCSPELAN4(nn.Module):\n",
    "    # csp-elan\n",
    "    def __init__(self, c1, c2, c3, c4, n=3,\n",
    "                 bias=False,\n",
    "                 act=\"silu\"):\n",
    "        super().__init__()\n",
    "        self.c = c3//2\n",
    "        self.cv1 = ConvNormLayer_fuse(c1, c3, 1, 1, bias=bias, act=act)\n",
    "        self.cv2 = nn.Sequential(CSPLayer(c3//2, c4, n, 1, bias=bias, act=act, bottletype=VGGBlock), ConvNormLayer_fuse(c4, c4, 3, 1, bias=bias, act=act))\n",
    "        self.cv3 = nn.Sequential(CSPLayer(c4, c4, n, 1, bias=bias, act=act, bottletype=VGGBlock), ConvNormLayer_fuse(c4, c4, 3, 1, bias=bias, act=act))\n",
    "        self.cv4 = ConvNormLayer_fuse(c3+(2*c4), c2, 1, 1, bias=bias, act=act)\n",
    "\n",
    "    def forward_chunk(self, x):\n",
    "        y = list(self.cv1(x).chunk(2, 1))\n",
    "        y.extend((m(y[-1])) for m in [self.cv2, self.cv3])\n",
    "        return self.cv4(torch.cat(y, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = list(self.cv1(x).split((self.c, self.c), 1))\n",
    "        y.extend(m(y[-1]) for m in [self.cv2, self.cv3])\n",
    "        return self.cv4(torch.cat(y, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c982d674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256, 20, 20])\n",
      "torch.Size([2, 256, 20, 20])\n",
      "torch.Size([2, 256, 40, 40])\n",
      "torch.Size([2, 256, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "lateral_convs = nn.ModuleList()\n",
    "fpn_blocks = nn.ModuleList()\n",
    "\n",
    "for _ in range(len(feats) - 1, 0, -1):\n",
    "    lateral_convs.append(ConvNormLayer_fuse(hidden_dim, hidden_dim, 1, 1))\n",
    "    fpn_blocks.append(\n",
    "        RepNCSPELAN4(hidden_dim * 2, hidden_dim, hidden_dim * 2, \n",
    "                     round(1 * hidden_dim // 2), \n",
    "                     round(3 * 2), act='silu')\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "# print(lateral_convs[len(feats) - 1 - 2])\n",
    "\n",
    "inner_outs = [proj_feats[-1]]\n",
    "print(inner_outs[0].shape)\n",
    "\n",
    "feat_high = inner_outs[0]\n",
    "feat_low = proj_feats[2 - 1]\n",
    "\n",
    "feat_high = lateral_convs[len(feats) - 1 - 2](feat_high)\n",
    "inner_outs[0] = feat_high\n",
    "print(inner_outs[0].shape)\n",
    "\n",
    "upsample_feat = F.interpolate(feat_high, scale_factor=2., mode='nearest')\n",
    "print(upsample_feat.shape)\n",
    "\n",
    "inner_out = fpn_blocks[len(feats) - 1 - 2](torch.concat([upsample_feat, feat_low], dim=1))\n",
    "print(inner_out.shape)\n",
    "inner_outs.insert(0, inner_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9dde829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCDown(nn.Module):\n",
    "    def __init__(self, c1, c2, k, s, act=None):\n",
    "        super().__init__()\n",
    "        self.cv1 = ConvNormLayer_fuse(c1, c2, 1, 1)\n",
    "        self.cv2 = ConvNormLayer_fuse(c2, c2, k, s, c2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cv2(self.cv1(x))\n",
    "\n",
    "downsample_convs = nn.ModuleList()\n",
    "pan_blocks = nn.ModuleList()\n",
    "\n",
    "for _ in range(len(feats) - 1):\n",
    "    downsample_convs.append(\n",
    "        nn.Sequential(SCDown(hidden_dim, hidden_dim, 3, 2, act='silu'))\n",
    "        )\n",
    "    pan_blocks.append(\n",
    "        RepNCSPELAN4(hidden_dim * 2, hidden_dim, hidden_dim * 2, round(1 * hidden_dim // 2), round(3 * 2), act='silu')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9279d2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_high: torch.Size([2, 256, 20, 20])\n",
      "downsample_feat: feat_low from : torch.Size([2, 256, 40, 40]) to : torch.Size([2, 256, 20, 20])\n",
      "torch.Size([2, 256, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "outs = [inner_outs[0]]\n",
    "feat_low = outs[-1]\n",
    "feat_high = inner_outs[1]\n",
    "\n",
    "print(f'feat_high: {feat_high.shape}')\n",
    "downsample_feat = downsample_convs[0](feat_low)\n",
    "print(f'downsample_feat: feat_low from : {feat_low.shape} to : {downsample_feat.shape}')\n",
    "out = pan_blocks[0](torch.concat([downsample_feat, feat_high], dim=1))\n",
    "print(out.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
