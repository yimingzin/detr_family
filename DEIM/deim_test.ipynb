{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97d38382",
   "metadata": {},
   "source": [
    "# backbone: PResNet or HGnetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10d5e4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 384, 80, 80])\n",
      "torch.Size([2, 768, 40, 40])\n",
      "torch.Size([2, 1536, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "S3 = torch.rand(size=(2, 384, 80, 80))\n",
    "S4 = torch.rand(size=(2, 768, 40, 40))\n",
    "S5 = torch.rand(size=(2, 1536, 20, 20))\n",
    "\n",
    "backbone_out = [S3, S4, S5]\n",
    "\n",
    "for i in backbone_out:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1d861a",
   "metadata": {},
   "source": [
    "# Hybrid Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e863ca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(act: str, inpace: bool=True):\n",
    "    \"\"\"get activation\n",
    "    \"\"\"\n",
    "    if act is None:\n",
    "        return nn.Identity()\n",
    "\n",
    "    elif isinstance(act, nn.Module):\n",
    "        return act\n",
    "\n",
    "    act = act.lower()\n",
    "\n",
    "    if act == 'silu' or act == 'swish':\n",
    "        m = nn.SiLU()\n",
    "\n",
    "    elif act == 'relu':\n",
    "        m = nn.ReLU()\n",
    "\n",
    "    elif act == 'leaky_relu':\n",
    "        m = nn.LeakyReLU()\n",
    "\n",
    "    elif act == 'silu':\n",
    "        m = nn.SiLU()\n",
    "\n",
    "    elif act == 'gelu':\n",
    "        m = nn.GELU()\n",
    "\n",
    "    elif act == 'hardsigmoid':\n",
    "        m = nn.Hardsigmoid()\n",
    "\n",
    "    else:\n",
    "        raise RuntimeError('')\n",
    "\n",
    "    if hasattr(m, 'inplace'):\n",
    "        m.inplace = inpace\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3598444",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNormLayer_fuse(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out, kernel_size, stride, g=1, padding=None, bias=False, act=None):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size-1)//2 if padding is None else padding\n",
    "        self.conv = nn.Conv2d(\n",
    "            ch_in,\n",
    "            ch_out,\n",
    "            kernel_size,\n",
    "            stride,\n",
    "            groups=g,\n",
    "            padding=padding,\n",
    "            bias=bias)\n",
    "        self.norm = nn.BatchNorm2d(ch_out)\n",
    "        self.act = nn.Identity() if act is None else get_activation(act)\n",
    "        self.ch_in, self.ch_out, self.kernel_size, self.stride, self.g, self.padding, self.bias = \\\n",
    "            ch_in, ch_out, kernel_size, stride, g, padding, bias\n",
    "\n",
    "    def forward(self, x):\n",
    "        if hasattr(self, 'conv_bn_fused'):\n",
    "            y = self.conv_bn_fused(x)\n",
    "        else:\n",
    "            y = self.norm(self.conv(x))\n",
    "        return self.act(y)\n",
    "\n",
    "    def convert_to_deploy(self):\n",
    "        if not hasattr(self, 'conv_bn_fused'):\n",
    "            self.conv_bn_fused = nn.Conv2d(\n",
    "                self.ch_in,\n",
    "                self.ch_out,\n",
    "                self.kernel_size,\n",
    "                self.stride,\n",
    "                groups=self.g,\n",
    "                padding=self.padding,\n",
    "                bias=True)\n",
    "\n",
    "        kernel, bias = self.get_equivalent_kernel_bias()\n",
    "        self.conv_bn_fused.weight.data = kernel\n",
    "        self.conv_bn_fused.bias.data = bias\n",
    "        self.__delattr__('conv')\n",
    "        self.__delattr__('norm')\n",
    "\n",
    "    def get_equivalent_kernel_bias(self):\n",
    "        kernel3x3, bias3x3 = self._fuse_bn_tensor()\n",
    "\n",
    "        return kernel3x3, bias3x3\n",
    "\n",
    "    def _fuse_bn_tensor(self):\n",
    "        kernel = self.conv.weight\n",
    "        running_mean = self.norm.running_mean\n",
    "        running_var = self.norm.running_var\n",
    "        gamma = self.norm.weight\n",
    "        beta = self.norm.bias\n",
    "        eps = self.norm.eps\n",
    "        std = (running_var + eps).sqrt()\n",
    "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
    "        return kernel * t, beta - running_mean * gamma / std\n",
    "\n",
    "\n",
    "class ConvNormLayer(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out, kernel_size, stride, g=1, padding=None, bias=False, act=None):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size-1)//2 if padding is None else padding\n",
    "        self.conv = nn.Conv2d(\n",
    "            ch_in,\n",
    "            ch_out,\n",
    "            kernel_size,\n",
    "            stride,\n",
    "            groups=g,\n",
    "            padding=padding,\n",
    "            bias=bias)\n",
    "        self.norm = nn.BatchNorm2d(ch_out)\n",
    "        self.act = nn.Identity() if act is None else get_activation(act)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.norm(self.conv(x)))\n",
    "    \n",
    "# TODO, add activation for cv1 following YOLOv10\n",
    "# self.cv1 = Conv(c1, c2, 1, 1)\n",
    "# self.cv2 = Conv(c2, c2, k=k, s=s, g=c2, act=False)\n",
    "class SCDown(nn.Module):\n",
    "    def __init__(self, c1, c2, k, s, act=None):\n",
    "        super().__init__()\n",
    "        self.cv1 = ConvNormLayer_fuse(c1, c2, 1, 1)\n",
    "        self.cv2 = ConvNormLayer_fuse(c2, c2, k, s, c2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cv2(self.cv1(x))\n",
    "\n",
    "\n",
    "class VGGBlock(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out, act='relu'):\n",
    "        super().__init__()\n",
    "        self.ch_in = ch_in\n",
    "        self.ch_out = ch_out\n",
    "        self.conv1 = ConvNormLayer(ch_in, ch_out, 3, 1, padding=1, act=None)\n",
    "        self.conv2 = ConvNormLayer(ch_in, ch_out, 1, 1, padding=0, act=None)\n",
    "        self.act = nn.Identity() if act is None else get_activation(act)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if hasattr(self, 'conv'):\n",
    "            y = self.conv(x)\n",
    "        else:\n",
    "            y = self.conv1(x) + self.conv2(x)\n",
    "\n",
    "        return self.act(y)\n",
    "\n",
    "    def convert_to_deploy(self):\n",
    "        if not hasattr(self, 'conv'):\n",
    "            self.conv = nn.Conv2d(self.ch_in, self.ch_out, 3, 1, padding=1)\n",
    "\n",
    "        kernel, bias = self.get_equivalent_kernel_bias()\n",
    "        self.conv.weight.data = kernel\n",
    "        self.conv.bias.data = bias\n",
    "        self.__delattr__('conv1')\n",
    "        self.__delattr__('conv2')\n",
    "\n",
    "    def get_equivalent_kernel_bias(self):\n",
    "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.conv1)\n",
    "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.conv2)\n",
    "\n",
    "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1), bias3x3 + bias1x1\n",
    "\n",
    "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
    "        if kernel1x1 is None:\n",
    "            return 0\n",
    "        else:\n",
    "            return F.pad(kernel1x1, [1, 1, 1, 1])\n",
    "\n",
    "    def _fuse_bn_tensor(self, branch: ConvNormLayer):\n",
    "        if branch is None:\n",
    "            return 0, 0\n",
    "        kernel = branch.conv.weight\n",
    "        running_mean = branch.norm.running_mean\n",
    "        running_var = branch.norm.running_var\n",
    "        gamma = branch.norm.weight\n",
    "        beta = branch.norm.bias\n",
    "        eps = branch.norm.eps\n",
    "        std = (running_var + eps).sqrt()\n",
    "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
    "        return kernel * t, beta - running_mean * gamma / std\n",
    "\n",
    "\n",
    "class CSPLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 num_blocks=3,\n",
    "                 expansion=1.0,\n",
    "                 bias=False,\n",
    "                 act=\"silu\",\n",
    "                 bottletype=VGGBlock):\n",
    "        super(CSPLayer, self).__init__()\n",
    "        hidden_channels = int(out_channels * expansion)\n",
    "        self.conv1 = ConvNormLayer_fuse(in_channels, hidden_channels, 1, 1, bias=bias, act=act)\n",
    "        self.conv2 = ConvNormLayer_fuse(in_channels, hidden_channels, 1, 1, bias=bias, act=act)\n",
    "        self.bottlenecks = nn.Sequential(*[\n",
    "            bottletype(hidden_channels, hidden_channels, act=act) for _ in range(num_blocks)\n",
    "        ])\n",
    "        if hidden_channels != out_channels:\n",
    "            self.conv3 = ConvNormLayer_fuse(hidden_channels, out_channels, 1, 1, bias=bias, act=act)\n",
    "        else:\n",
    "            self.conv3 = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_2 = self.conv2(x)\n",
    "        x_1 = self.conv1(x)\n",
    "        x_1 = self.bottlenecks(x_1)\n",
    "        return self.conv3(x_1 + x_2)\n",
    "\n",
    "class RepNCSPELAN4(nn.Module):\n",
    "    # csp-elan\n",
    "    def __init__(self, c1, c2, c3, c4, n=3,\n",
    "                 bias=False,\n",
    "                 act=\"silu\"):\n",
    "        super().__init__()\n",
    "        self.c = c3//2\n",
    "        self.cv1 = ConvNormLayer_fuse(c1, c3, 1, 1, bias=bias, act=act)\n",
    "        self.cv2 = nn.Sequential(CSPLayer(c3//2, c4, n, 1, bias=bias, act=act, bottletype=VGGBlock), ConvNormLayer_fuse(c4, c4, 3, 1, bias=bias, act=act))\n",
    "        self.cv3 = nn.Sequential(CSPLayer(c4, c4, n, 1, bias=bias, act=act, bottletype=VGGBlock), ConvNormLayer_fuse(c4, c4, 3, 1, bias=bias, act=act))\n",
    "        self.cv4 = ConvNormLayer_fuse(c3+(2*c4), c2, 1, 1, bias=bias, act=act)\n",
    "\n",
    "    def forward_chunk(self, x):\n",
    "        y = list(self.cv1(x).chunk(2, 1))\n",
    "        y.extend((m(y[-1])) for m in [self.cv2, self.cv3])\n",
    "        return self.cv4(torch.cat(y, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = list(self.cv1(x).split((self.c, self.c), 1))\n",
    "        y.extend(m(y[-1]) for m in [self.cv2, self.cv3])\n",
    "        return self.cv4(torch.cat(y, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a1dc96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# transformer\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 d_model,\n",
    "                 nhead,\n",
    "                 dim_feedforward=2048,\n",
    "                 dropout=0.1,\n",
    "                 activation=\"relu\",\n",
    "                 normalize_before=False):\n",
    "        super().__init__()\n",
    "        self.normalize_before = normalize_before\n",
    "\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout, batch_first=True)\n",
    "\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.activation = get_activation(activation)\n",
    "\n",
    "    @staticmethod\n",
    "    def with_pos_embed(tensor, pos_embed):\n",
    "        return tensor if pos_embed is None else tensor + pos_embed\n",
    "\n",
    "    def forward(self, src, src_mask=None, pos_embed=None) -> torch.Tensor:\n",
    "        residual = src\n",
    "        if self.normalize_before:\n",
    "            src = self.norm1(src)\n",
    "        q = k = self.with_pos_embed(src, pos_embed)\n",
    "        src, _ = self.self_attn(q, k, value=src, attn_mask=src_mask)\n",
    "\n",
    "        src = residual + self.dropout1(src)\n",
    "        if not self.normalize_before:\n",
    "            src = self.norm1(src)\n",
    "\n",
    "        residual = src\n",
    "        if self.normalize_before:\n",
    "            src = self.norm2(src)\n",
    "        src = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
    "        src = residual + self.dropout2(src)\n",
    "        if not self.normalize_before:\n",
    "            src = self.norm2(src)\n",
    "        return src\n",
    "\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, encoder_layer, num_layers, norm=None):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([copy.deepcopy(encoder_layer) for _ in range(num_layers)])\n",
    "        self.num_layers = num_layers\n",
    "        self.norm = norm\n",
    "\n",
    "    def forward(self, src, src_mask=None, pos_embed=None) -> torch.Tensor:\n",
    "        output = src\n",
    "        for layer in self.layers:\n",
    "            output = layer(output, src_mask=src_mask, pos_embed=pos_embed)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            output = self.norm(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9084868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class HybridEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels=[512, 1024, 2048],\n",
    "                 feat_strides=[8, 16, 32],\n",
    "                 hidden_dim=256,\n",
    "                 nhead=8,\n",
    "                 dim_feedforward = 1024,\n",
    "                 dropout=0.0,\n",
    "                 enc_act='gelu',\n",
    "                 use_encoder_idx=[2],\n",
    "                 num_encoder_layers=1,\n",
    "                 pe_temperature=10000,\n",
    "                 expansion=1.0,\n",
    "                 depth_mult=1.0,\n",
    "                 act='silu',\n",
    "                 eval_spatial_size=None,\n",
    "                 version='dfine',\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.feat_strides = feat_strides\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.use_encoder_idx = use_encoder_idx\n",
    "        self.num_encoder_layers = num_encoder_layers\n",
    "        self.pe_temperature = pe_temperature\n",
    "        self.eval_spatial_size = eval_spatial_size\n",
    "        self.out_channels = [hidden_dim for _ in range(len(in_channels))]\n",
    "        self.out_strides = feat_strides\n",
    "\n",
    "        # channel projection\n",
    "        self.input_proj = nn.ModuleList()\n",
    "        for in_channel in in_channels:\n",
    "            proj = nn.Sequential(OrderedDict([\n",
    "                    ('conv', nn.Conv2d(in_channel, hidden_dim, kernel_size=1, bias=False)),\n",
    "                    ('norm', nn.BatchNorm2d(hidden_dim))\n",
    "                ]))\n",
    "\n",
    "            self.input_proj.append(proj)\n",
    "\n",
    "        # encoder transformer\n",
    "        encoder_layer = TransformerEncoderLayer(\n",
    "            hidden_dim,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            activation=enc_act\n",
    "            )\n",
    "\n",
    "        self.encoder = nn.ModuleList([\n",
    "            TransformerEncoder(copy.deepcopy(encoder_layer), num_encoder_layers) for _ in range(len(use_encoder_idx))\n",
    "        ])\n",
    "\n",
    "        # top-down fpn\n",
    "        self.lateral_convs = nn.ModuleList()\n",
    "        self.fpn_blocks = nn.ModuleList()\n",
    "        for _ in range(len(in_channels) - 1, 0, -1):\n",
    "            # TODO, add activation for those lateral convs\n",
    "            if version == 'dfine':\n",
    "                self.lateral_convs.append(ConvNormLayer_fuse(hidden_dim, hidden_dim, 1, 1))\n",
    "            else:\n",
    "                self.lateral_convs.append(ConvNormLayer_fuse(hidden_dim, hidden_dim, 1, 1, act=act))\n",
    "            self.fpn_blocks.append(\n",
    "                RepNCSPELAN4(hidden_dim * 2, hidden_dim, hidden_dim * 2, round(expansion * hidden_dim // 2), round(3 * depth_mult), act=act) \\\n",
    "                if version == 'dfine' else CSPLayer(hidden_dim * 2, hidden_dim, round(3 * depth_mult), act=act, expansion=expansion, bottletype=VGGBlock)\n",
    "            )\n",
    "\n",
    "        # bottom-up pan\n",
    "        self.downsample_convs = nn.ModuleList()\n",
    "        self.pan_blocks = nn.ModuleList()\n",
    "        for _ in range(len(in_channels) - 1):\n",
    "            self.downsample_convs.append(\n",
    "                nn.Sequential(SCDown(hidden_dim, hidden_dim, 3, 2, act=act)) \\\n",
    "                if version == 'dfine' else ConvNormLayer_fuse(hidden_dim, hidden_dim, 3, 2, act=act)\n",
    "            )\n",
    "            self.pan_blocks.append(\n",
    "                RepNCSPELAN4(hidden_dim * 2, hidden_dim, hidden_dim * 2, round(expansion * hidden_dim // 2), round(3 * depth_mult), act=act) \\\n",
    "                if version == 'dfine' else CSPLayer(hidden_dim * 2, hidden_dim, round(3 * depth_mult), act=act, expansion=expansion, bottletype=VGGBlock)\n",
    "            )\n",
    "\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        if self.eval_spatial_size:\n",
    "            for idx in self.use_encoder_idx:\n",
    "                stride = self.feat_strides[idx]\n",
    "                pos_embed = self.build_2d_sincos_position_embedding(\n",
    "                    self.eval_spatial_size[1] // stride, self.eval_spatial_size[0] // stride,\n",
    "                    self.hidden_dim, self.pe_temperature)\n",
    "                setattr(self, f'pos_embed{idx}', pos_embed)\n",
    "                # self.register_buffer(f'pos_embed{idx}', pos_embed)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_2d_sincos_position_embedding(w, h, embed_dim=256, temperature=10000.):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        grid_w = torch.arange(int(w), dtype=torch.float32)\n",
    "        grid_h = torch.arange(int(h), dtype=torch.float32)\n",
    "        grid_w, grid_h = torch.meshgrid(grid_w, grid_h, indexing='ij')\n",
    "        assert embed_dim % 4 == 0, \\\n",
    "            'Embed dimension must be divisible by 4 for 2D sin-cos position embedding'\n",
    "        pos_dim = embed_dim // 4\n",
    "        omega = torch.arange(pos_dim, dtype=torch.float32) / pos_dim\n",
    "        omega = 1. / (temperature ** omega)\n",
    "\n",
    "        out_w = grid_w.flatten()[..., None] @ omega[None]\n",
    "        out_h = grid_h.flatten()[..., None] @ omega[None]\n",
    "\n",
    "        return torch.concat([out_w.sin(), out_w.cos(), out_h.sin(), out_h.cos()], dim=1)[None, :, :]\n",
    "\n",
    "    def forward(self, feats):\n",
    "        assert len(feats) == len(self.in_channels)\n",
    "        proj_feats = [self.input_proj[i](feat) for i, feat in enumerate(feats)]\n",
    "\n",
    "        # encoder\n",
    "        if self.num_encoder_layers > 0:\n",
    "            for i, enc_ind in enumerate(self.use_encoder_idx):\n",
    "                h, w = proj_feats[enc_ind].shape[2:]\n",
    "                # flatten [B, C, H, W] to [B, HxW, C]\n",
    "                src_flatten = proj_feats[enc_ind].flatten(2).permute(0, 2, 1)\n",
    "                if self.training or self.eval_spatial_size is None:\n",
    "                    pos_embed = self.build_2d_sincos_position_embedding(\n",
    "                        w, h, self.hidden_dim, self.pe_temperature).to(src_flatten.device)\n",
    "                else:\n",
    "                    pos_embed = getattr(self, f'pos_embed{enc_ind}', None).to(src_flatten.device)\n",
    "\n",
    "                memory :torch.Tensor = self.encoder[i](src_flatten, pos_embed=pos_embed)\n",
    "                proj_feats[enc_ind] = memory.permute(0, 2, 1).reshape(-1, self.hidden_dim, h, w).contiguous()\n",
    "\n",
    "        # broadcasting and fusion\n",
    "        inner_outs = [proj_feats[-1]]\n",
    "        for idx in range(len(self.in_channels) - 1, 0, -1):\n",
    "            feat_heigh = inner_outs[0]\n",
    "            feat_low = proj_feats[idx - 1]\n",
    "            feat_heigh = self.lateral_convs[len(self.in_channels) - 1 - idx](feat_heigh)\n",
    "            inner_outs[0] = feat_heigh\n",
    "            upsample_feat = F.interpolate(feat_heigh, scale_factor=2., mode='nearest')\n",
    "            inner_out = self.fpn_blocks[len(self.in_channels)-1-idx](torch.concat([upsample_feat, feat_low], dim=1))\n",
    "            inner_outs.insert(0, inner_out)\n",
    "\n",
    "        outs = [inner_outs[0]]\n",
    "        for idx in range(len(self.in_channels) - 1):\n",
    "            feat_low = outs[-1]\n",
    "            feat_height = inner_outs[idx + 1]\n",
    "            downsample_feat = self.downsample_convs[idx](feat_low)\n",
    "            out = self.pan_blocks[idx](torch.concat([downsample_feat, feat_height], dim=1))\n",
    "            outs.append(out)\n",
    "\n",
    "        return outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da4bdadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256, 80, 80])\n",
      "torch.Size([2, 256, 40, 40])\n",
      "torch.Size([2, 256, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "hybrid_encoder_instance = HybridEncoder(in_channels=[384, 768, 1536])\n",
    "outs = hybrid_encoder_instance(backbone_out)\n",
    "for i in outs:\n",
    "    print(i.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
